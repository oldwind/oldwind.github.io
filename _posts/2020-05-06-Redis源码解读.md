---
layout: content
title: redis源码解读
status: 1
category: redis, c
author:   "yimuren"
tags:
    - c
---

## 一. 前言

### 1.1 redis简介

**百度百科**

> Redis（Remote Dictionary Server)，即远程字典服务，是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。 


**维基百科**


```bash
开发者  Salvatore Sanfilippo 
初始版本	2009年5月10日，​10年前
稳定版本	6.0.1（2020年5月1日，​4天前 [1]）
预览版本	6.0 RC4（2020年4月16日，​19天前 [2]）
源代码库	github.com/antirez/redis
编程语言	ANSI C
操作系统	跨平台
语言	英语
类型	非关系型数据库
许可协议	BSD
网站	redis.io
```

### 1.2 redis的应用

作为key-value数据库，redis的"value"，支持多种数据结构，有 string，list，hash, set, zset, bitmaps, hyperloglogs, geospatial indexe .丰富的数据结构，高效率的内存查询，以及支持灵活的lua脚本和事物 支持redis在越来越多的场景下得到广泛应用

在这里简单的举一些使用的例子

#### 1.2.1 分布式锁

锁的出现是解决某些资源不允许并发访问的需求，例如数据库的行数据(行级锁)、表数据(表级锁)，锁的实现方式有多种方式，有数据库锁、redis锁、单机情况下可以采用文件锁，实现redis分布式锁的方式有两种

##### 1.2.1.1 setnx实现分布式锁

setnx 是 set if not exsit， 如果不存在则set，用在锁上，可以多个进程尝试去 setnx, 那么则只有一个尝试成功，用伪代码表示一下加锁的过程

```bash
    set ok =  setnx(key, value); 
    if ok {
        doSomething();  
        del(key);  // 删除锁
    } else {
        ...
    }
```

但是很明显，如果doSomething()过程中，进程断了 或者 del() 过程中失败，将会导致锁无法释放，这个过程中，将增加失效时间来解决锁的异常释放问题

```bash
    set ok =  setnx(key, value); 
    if ok {
        expire(key, second); // 增加失效时间
        doSomething();  
        del(key);  // 删除锁
    } else {
        ...
    }
```

增加失效时间后，发现setnx 和 expire 突然不是原子操作了，那么同样存在，setnx成功后，进程断了，锁将永远不会被释放的情况, 为了解决这个原子性的问题，有很多方案被考虑， redis支持lua操作，可以用lua脚本来实现原子性， 或者 用redis的事物，但是redis的事物后面会分析一下源码，实际上redis的事物只是在server端设计了一个队列，将redis指令的操作放到队列里面，一次性在server端执行了，所以没有mvcc，没有事物的回滚机制，并没有解决redis锁设定的原子性问题

这个时候，可以看看set 命令来实现锁

##### 1.2.1.2 set 指令对锁的实现

`set key value [EX seconds] [PX milliseconds] [NX|XX]`

从 Redis 2.6.12 版本开始, redis的set指令实际上把 setnx，setex, psetex 指令功能做了合并

- EX 表示秒级别失效
- PX 表示毫米级别失效
- NX 表示不存在则操作
- XX 表示存在则操作 

关于锁失效的时间和doSomething()的事件设计问题，这里不再细谈，那么redis的set命令实现了锁操作的原子性(?)， 后面通过源码我们分析一下

#### 1.2.2 排行榜

做排行榜的方式有很多，基于数据库的，基于redis的，基于日志分析的流式计算的, 如果排行榜要求在高并发情况下时延最低，那么redis肯定是"不二人选"，redis做排行榜基于的是它 value的 zset数据结构，也就是 排序集合，首先集合解决了重复key问题，排序方式可以在内存中快速获取top数据

```bash
127.0.0.1:6379> zadd rank-guess 40 tom
(integer) 1
127.0.0.1:6379> zadd rank-guess 30 Ben
(integer) 1
127.0.0.1:6379> zadd rank-guess 30 jordon
(integer) 1
127.0.0.1:6379> zadd rank-guess 10 john
(integer) 1
127.0.0.1:6379>
127.0.0.1:6379> zrange rank-guess 0 1
1) "john"
2) "Ben"
127.0.0.1:6379> zrange rank-guess 0 1 withscores
1) "john"
2) "10"
3) "Ben"
4) "30"
127.0.0.1:6379> zrevrange rank-guess 0 1 withscores
1) "tom"
2) "40"
3) "jordon"
4) "30"
```

redis 做排行榜非常简单，zadd创建一个榜单，zrange可以正序获取榜单数据，zrevrange 从后截取榜单数据

- zadd  `zadd key [NX|XX] [CH] [INCR] score member [score member ...]`
- zrange  `zrange key start stop [WITHSCORES]`
- zrevrange `zrevrange key start stop [WITHSCORES]`

我们从redis的zadd命令中可以看出，zadd还支持对榜单的元素做自增操作，非常方便

```bash
127.0.0.1:6379> zadd rank-guess incr 1 jordon
"31"
127.0.0.1:6379> zrevrange rank-guess 0 1 withscores
1) "tom"
2) "40"
3) "jordon"
4) "31"
```

#### 1.2.3 简单队列

**首先说，redis并不适合做队列** 

原因在我看来主要是redis在"断电"情况下可能出现的丢消息情况，redis设计的初衷是cache，cache的作用是最大可能的提升性能，所以redis作者在设计中，尽可能的进行内存操作，而不是先持久化，后在进行内存操作，在这种情况下，势必存在，redis进程在中断情况下，又没有将消息持久化，在redis重启后，消息丢失； redis对数据持久化的话题，我们在后面再详细分析

同时，redis的作者也考虑了这个问题，设计了 一个消息队列disque： antirez/disque 专门用于队列使用，这个在redis高版本的时候将有可能会使用

##### 1.2.3.1 list队列

常见的redis做队列的方式是利用redis中的list，list的特点是，很方便在头节点和尾节点插入和查询数据，我们来看一下list的操作指令

- `LPUSH key value [value …]`
- `LPUSHX key value`
- `RPUSH key value [value …]`
- `RPUSHX key value`
- `LPOP key`
- `RPOP key`
- `RPOPLPUSH source destination`
- `LREM key count value`    根据参数 count 的值，移除列表中与参数 value 相等的元素。
- `LLEN key` 返回队列的长度

...

redis的命令中 "L" 表示队列的左边， "R" 表示队列的右边，左右可以做前后理解，在做队列的时候，可以支持 1对1 的关系，也就是一个生产者 对 一个消费者， 生产和消费的顺序开发者可以设计

```bash
127.0.0.1:6379> LPUSH myqueue a
(integer) 1
(5.19s)
127.0.0.1:6379>
127.0.0.1:6379> LPUSH myqueue b
(integer) 2
(2.88s)
127.0.0.1:6379> RPop myqueue
"a"
(2.27s)
127.0.0.1:6379> LLEN myqueue
(integer) 1
(2.75s)
```

##### 1.2.3.2 pub/sub

redis作者提供了 发布和订阅 模型(pub/sub), 可以解决 多个生产者 对 多个消费者的情况, 我们看一下下面一张图

![]({{site.baseurl}}/img/tech/2020-05-09-16-30-15.png)

pub/sub模型，用于消息的订阅和推送，涉及三个角色

- 生产者
- 频道
- 消费者

消费者可以一次性订阅多个频道，例如图中，消费者可以 订阅 CCTV1 CCTV2

```bash
127.0.0.1:6379> subscribe CCTV1 CCTV2
```

消费者的订阅，实际是一次客户端对服务端的长连接，如果连接断了，那么客户端就收不到服务端发的消息，包括历史消息， 消息并不会被持久化， 生产者在publish消息的时候，一次只能给一个频道 publish 消息， publish成功后，所有订阅这个频道的连接，将都会收到消息


```bash
127.0.0.1:6379>  publish CCTV1 "cctv1 is good1"
(integer) 2
(2.88s)
```
如上面，返回值可以清楚的看出来，有两个消费者收到了消息

pub/sub模型解决了消息的多对多发送问题，但是消息看起来不会持久化，在使用过程中，如果连接断了，那么将丢失这段事件生产者发送的消息。 

总的来说，实现队列的方案有很多，redis，mysql，kafaka，甚至文件，都能实现队列，选择什么样的技术和业务是息息相关，如果业务对消息的小概率丢失并不是很关心，那么redis不妨是一种好的选择

#### 1.2.4 计数器

计数器在很多业务中得到应用, 例如防止用户刷单、流量控制，包括前面说的排行榜，实际都是计数器功能的体现，这里说计数器主要说说redis实现计数器的方法

##### 1.2.4.1 字符串方案

```bash
127.0.0.1:6379> INCR example
(integer) 1
127.0.0.1:6379> GET example
"1"
```

通常选择`INCR` 指令来操作 指定 key的计数加一，如果需要加大于1的数，可以使用`INCRBY`指令

```bash
127.0.0.1:6379> INCRBY example 10
(integer) 11
127.0.0.1:6379> GET example
"11"
127.0.0.1:6379> DECR example
(integer) 10
127.0.0.1:6379> GET example
"10"
```

为什么选择`INCR`指令而不是先`GET` 后`SET`呢，实际就是防止数据出现"脏读"的情况，`INCR`提供了数据的原子操作

##### 1.2.4.2 hashtable方案

`HINCRBY KEY FIELD increment`

- 对hash表 KEY 中的变量 FIELD 增加 `increment`
- `increment`可以是正数，也可以是负数，负数则实现了 `DECR`的功能
- KEY 不存在，会自动创建
- FIELD 不存在，默认是0
- FIELD 如果是字符串 被加数值 操作，会报错

```bash
127.0.0.1:6379> HINCRBY example2 ex 10
(integer) 10
127.0.0.1:6379> HGET example2 ex
"10"
127.0.0.1:6379> HINCRBY example2 ex -9
(integer) 1
127.0.0.1:6379> HGET example2 ex
"1"
127.0.0.1:6379> HINCRBY example2 ex -10
(integer) -9
127.0.0.1:6379> HGET example2 ex
"-9"
127.0.0.1:6379> HINCRBY example2 ex 12
(integer) 3
```

#### 1.2.5 session保存

http协议在会话过程中是无状态的，例如要实现一次请求的赋值操作在下次请求过程中可以使用到，那么则需要Session的方案，session的实现实际比较简单，我们用php来举个例子

通常情况下，下面的代码能够实现一个Session服务, 我们假设入口脚本是a.php

```php
<?php
  session_start();
  $_SESSION["key1"] = "value1";
```

![]({{site.baseurl}}/img/tech/2020-05-19-15-11-17.png)

交互图已经描写通过session实现交互的过程，

1. a.php文件生成sessid，做为key，可以存储方式有很多，例如本地文件、缓存(redis 或 memcache) 或者数据库等等
2. 服务端会通知客户端在cookie里面记录一下这个sessid，做为后续交互的"票证"
3. 客户端在请求b.php过程中，服务端可以通过sessid从服务端存储的位置获取到上次会话记录的信息

php在默认情况下，是通过本地文件的方式来存储session信息，这明显有一个问题，客户端在请求服务端的时候，如果没有做ip hash等方式，客户端的请求会落在服务端的不同服务器上，那么服务端就无法获取上次请求通过session的赋值了，这种情况下，将session做集中化的存取就是非常必要的，php提供了两种方式来快速简单实现session的集中化存取

1. 方式一 通过php.ini的配置

```bash　　
session.save_handler = redis
session.save_path = "tcp://127.0.0.1:6379"
```

2. 方式二 在代码中设定

```php
<?php
    ini_set("session.save_handler", "redis");
　　 ini_set("session.save_path", "tcp://127.0.0.1:6379");  
```



### 1.3 缓存市场分析

关于缓存市场，主要是memcache 和 redis，由于redis的开源和丰富的功能特性，使得redis的市场规模越来越大，这里就支持的数据结构、持久化、线程模型、网络模型、内存分配，存储value大小等多方面比较一下memcache和redis的差异

| | Memcached | Redis |
|------|-----|----|
| <span style="width:60px; display:inline-block;">简介</span> | Memcached是一套分布式的高速缓存系统，由LiveJournal的Brad Fitzpatrick开发，但当前被许多网站使用。这是一套开放源代码软件，以BSD license授权发布。memcached缺乏认证以及安全管制，这代表应该将memcached服务器放置在防火墙后 | Redis（Remote Dictionary Server)，即远程字典服务，是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助 | 
| 支持的数据结构 |  只支持简单的key/value数据结构   |  string，list，hash, set, zset, bitmaps, hyperloglogs, geospatial indexe .etc | 
| 存储value的大小 | 最大是1M | `String类型：`一个String类型的value最大可以存储512M; `List类型：`list的元素个数最多为2^32-1个，也就是4294967295个; `Set类型：`元素个数最多为2^32-1个，也就是4294967295个; `Hash类型：`键值对个数最多为2^32-1个，也就是4294967295个; `Sorted set类型：`跟Set类型相似。|
| 线程模型 | 多线程模型，主线程listen，多个work子线程进行处理, 虽然有可能需要考虑锁的消耗、但是性能会比redis高一些 | redis在处理读写的时候是单线程模型 |
| IO | 非阻塞I/0多路复用 | 非阻塞I/0多路复用  |
| 集群部署 | 需要自己实现类似一致性hash的负载均衡算法解决集群问题，扩展性比较低| 支持高可用集群，支持主从|
| 容灾-持久化 | 存内存存储，不支持持久化 | 支持持久化，有aof 和 rdb(快照) 两种方案 |

## 二. redis的源码初探

在前面看了redis的一些常见使用场景，在这节主要的目的是对redis源码做一些分析，分析redis源码按照下面的主要流程进行

1. 源码下载 https://github.com/antirez/redis
2. 编译debug版本 可以阅读一下redis的makefile，执行make
3. 边看边执行代码，

### 2.1 源码结构

查看一下redis的目录树

- `src` 目录是redis的核心代码目录
- `deps` 目录是redis依赖的第三方功能，例如lua脚本支持，内存管理等等
- `tests` 单元测试目录
- `redis.conf` redis的配置文件
- `sentinel.conf` redis的哨兵配置文件
- `utils` redis的工具实现

```bash
-rw-rw-r--   1 work work 93478 Mar 31 18:02 00-RELEASENOTES
-rw-r--r--   1 work work    53 Mar 30 18:06 BUGS
-rw-rw-r--   1 work work  1805 Mar 31 18:02 CONTRIBUTING
-rw-r--r--   1 work work  1487 Mar 30 18:06 COPYING
-rw-r--r--   1 work work    11 Mar 30 18:06 INSTALL
-rw-rw-r--   1 work work  4223 Mar 31 13:56 MANIFESTO
-rw-r--r--   1 work work   151 Mar 30 18:06 Makefile
-rw-rw-r--   1 work work  6834 Mar 31 18:02 README.md
drwxr-xr-x  13 work work   416 Mar 31 18:02 deps
-rw-rw-r--   1 work work 46695 Mar 31 18:02 redis.conf
-rw-rw-r--   1 work work  7971 Apr  8 10:57 sentinel.conf
drwxr-xr-x 178 work work  5696 Mar 31 18:04 src
drwxr-xr-x  12 work work   384 Mar 31 18:02 tests
drwxr-xr-x  18 work work   576 Mar 31 18:02 utils
```

redis里面的deps文件夹，进去看一下，make的时候


```bash
|-- deps
|   |-- Makefile
|   |-- README.md
|   |-- geohash-int
|   |-- hiredis
|   |-- jemalloc
|   |-- linenoise
|   |-- lua
|   `-- update-jemalloc.sh
```

### 2.2 redis的服务介绍

## 三. redis的数据结构和算法

> Pascal之父——Nicklaus  "算法+数据结构=程序"

分析redis的源码，需要从redis基础的数据结构和算法开始，


- 网络
- 存储
    - sds
    - ziplist
    - 
- 集群管理
- 通用工具

### 3.1 ae

**`ae`**： 作者的定义是 "A simple event-driven programming library "， 一个简单的事件驱动库.

redis 的作者把事件定义为两种：

- 一种是 aeFileEvent 称之为 文件事件，实际上，主要是处理socket fd 的事件
- 另外一种是 aeTimeEvent 可以称之为 时间事件

另外redis还设计了一个数据结构 aeFiredEvent 存储被激活的事件




### 3.2 adlist

**`adlist`** : “ A generic doubly linked list implementation ”, adlist 是 redis作者实现的一个双向链表, 这个双向链表非常简单，包含两部分元素

1. `list` 管理双向链表"节点"
2. `listNode` 双向链表的节点，每个节点有两个指针，指向前后元素，头节点的前元素是`null`, 


```c
typedef struct listNode {
    struct listNode *prev;
    struct listNode *next;
    void *value;
} listNode;

typedef struct list {
    listNode *head;
    listNode *tail;
    void *(*dup)(void *ptr);
    void (*free)(void *ptr);
    int (*match)(void *ptr, void *key);
    unsigned long len;
} list;

```

![]({{site.baseurl}}/img/tech/2020-05-07-16-52-43.png)


adlist的双向链表设计在多处使用到, 例如，server启动后，连接的 client， 实际上，这个数据结构并不是用在redis的value对list的支持上

### 3.3 quicklist




### 3.4 dict

dict是redis对hashtable的具体实现，hash冲撞采用比较传统的“开链法”，但是在基础上做了升级，我想作者重点考虑了下面几个问题

1. 如何解决，hash表元素达到一定规模，冲撞过程中的元素形成的链表越来越长，影响性能的问题？
2. k-v结构中value类型是整形和字符串的区别, 如何提升性能问题？

解决冲突导致的"开链"，链表的长度越长，在find查找过程中，即便查到元素所在的bucket，也需要遍历链表查找元素是存在，这里面对性能影响有两个方面

1. 遍历过程中需要多次比较元素，
2. 遍历链表中查找下一个元素的寻址问题。

![]({{site.baseurl}}/img/tech/2020-05-07-17-43-10.png)

如何提高性能呢？

我想redis的作者在考虑这个问题的时候，给出了他的方案

#### 3.4.1 rehash

rehash是一种扩容方案，假设我们的hash表bucket的数量是4，如果只有4个元素，经过hash计算，较为平均的分配在各个bucket中，性能比较棒，而如今，元素的个数增长到40个，很显然hash冲突比较多，性能降低，在这个时候redis考虑增加bucket的数量，缓步将原来bucket的元素迁移到现在的bucket中，这个就是redis作者设计的rehash

那么如何进行rehash呢？ 如何触发rehash呢？ 以及什么时候需要rehash呢(推动)？

**第一个问题：如何进行rehash**

传统的hashtable设计可以是看是 `dictht` 到 `dictEntry` 两个数据结构设计实现， redis作者在这个基础上，增加`dict`结构，`dict`设计了 `dictht ht[2]` 数组来做rehash过程中的"新旧"替换， 由于hashtable的bucket数量有可能非常庞大，那么就不适合一次性rehash，需要缓步做，所以作者设计了 `rehashidx`， 这个字段类似一个游标，当字段是 -1 的时候，表示没有在rehash，其它表示在rehash中，并且表示rehash中 ht[0]的bucket数组的index, 在rehash的过程中，ht[0]是"旧" hashtable， ht[1]是 "新" hashtable

我们先大致的看一下rehash流程

- a. 先看一下rehash 函数的设计， 我做了一下输入参数的注释

```c
// d ：需要做rehash的节点
// n ：处理ht[0]的bucket的数量
int dictRehash(dict *d, int n) {
```

- b. 用户传了参数，希望处理 n 个bucket，但是这些bucket有些是空的，那么这次处理没有达到最有效的目的，所以在这个时候，作者做了一些优化设计
    - 增加 empty_visits 变量记录 空bucket的个数，处理空 bucket的上限是 10 * n， n 是前面说的用户传进来计划迁移的ht[0]的bucket个数
    - 所以说，如果用户计划迁移ht[0]中n个bucket，实际有可能处理11 * n - 1 个bucket上限

- c. ht[0]旧的bucket的元素都迁移完到ht[1]后，将ht[0] 和 ht[0]的指针元素做个互换，完成rehash

![]({{site.baseurl}}/img/tech/2020-05-07-19-52-35.png)

结合前面的流程，可以很清楚的看出来`dictRehash(dict *d, int n)`, 不仅仅支持扩容，同样支持缩容，如何使用，取决用户的调用


**第二个问题：如何触发rehash**

如前面所述，rehash适用于"扩容"和"缩容"，那么什么时候触发rehash呢，先来看看

**1. 缩容** 

redis作者设计了一个方法来判断是否需要进行缩容，我们看一下下面的代码，其中 HASHTABLE_MIN_FILL 值在redis中定的是10， 实际上是

- bucket的数量 > 4
- hash的成员数量(使用量 used) / bucket数量 (size) < 10 % 

在这两个前提下需要进行调整hashtable的大小，那么调整的bucket个数是多少呢？ 选择的是比used 大的，并且最接近used的 2 的n次幂，当然也要满足在设计的边界以内

```c
int htNeedsResize(dict *dict) {
    long long size, used;

    size = dictSlots(dict);
    used = dictSize(dict);
    return (size > DICT_HT_INITIAL_SIZE &&
            (used*100/size < HASHTABLE_MIN_FILL));
}
```

那么什么时候触发缩容呢？
主要在dict的元素减少的情况下， 例如

- k-v 结构，如果v 是`hash` 结构，从`hash`中删除元素的时候 `int hashTypeDelete(robj *o, robj *field) `
- k-v 结构，如果v 是`set` 结构，需要从 `set` 中删除元素 `int setTypeRemove(robj *setobj, robj *value) `

当然还有一些其它地方，主要是dict的元素数量减少到一定程度，需要触发`缩容`

**2. 扩容**

什么时候触发扩容，实际上很容易理解，必然是元素增加的情况下， dict的元素增加，走的统一的 api，

- `dictEntry *dictAddRaw(dict *d, void *key)`

我们把调用扩容的函数调用栈打印一下，了解一下扩容的逻辑

```bash
(gdb) bt
#0  _dictKeyIndex (key=<optimized out>, d=<optimized out>) at dict.c:980
#1  dictAddRaw (d=d@entry=0x7ffff6e181e0, key=0x7ffff6eb3491) at dict.c:356
#2  0x0000000000423f8f in dictAdd (d=0x7ffff6e181e0, key=<optimized out>, val=val@entry=0x7ffff6e17bc0) at dict.c:324
#3  0x000000000043adc5 in dbAdd (db=0x7ffff6e27800, key=0x7ffff6e1b120, val=0x7ffff6e17bc0) at db.c:159
#4  0x000000000043b305 in setKey (db=0x7ffff6e27800, key=key@entry=0x7ffff6e1b120, val=val@entry=0x7ffff6e17bc0) at db.c:186
#5  0x0000000000444e68 in setGenericCommand (c=c@entry=0x7ffff6f4e680, flags=flags@entry=0, key=0x7ffff6e1b120,
    val=0x7ffff6e17bc0, expire=expire@entry=0x0, unit=unit@entry=0, ok_reply=ok_reply@entry=0x0,
    abort_reply=abort_reply@entry=0x0) at t_string.c:86
#6  0x000000000044506f in setCommand (c=0x7ffff6f4e680) at t_string.c:139
#7  0x0000000000427bc5 in call (c=c@entry=0x7ffff6f4e680, flags=flags@entry=15) at server.c:2265
#8  0x000000000042ac87 in processCommand (c=0x7ffff6f4e680) at server.c:2544
#9  0x0000000000437765 in processInputBuffer (c=0x7ffff6f4e680) at networking.c:1311
#10 0x00000000004221e0 in aeProcessEvents (eventLoop=eventLoop@entry=0x7ffff6e36050, flags=flags@entry=3) at ae.c:431
#11 0x00000000004224ab in aeMain (eventLoop=0x7ffff6e36050) at ae.c:489
#12 0x000000000041f3d0 in main (argc=2, argv=0x7fffffffe748) at server.c:4133
```

走进`_dictKeyIndex()`，在dict增加元素的时候，都会通过 `_dictExpandIfNeeded()` 函数查看是否需要扩容

```c
static unsigned int dict_force_resize_ratio = 5;

...

static int _dictExpandIfNeeded(dict *d)
{
    /* Incremental rehashing already in progress. Return. */
    if (dictIsRehashing(d)) return DICT_OK;

    /* If the hash table is empty expand it to the initial size. */
    if (d->ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE);

    /* If we reached the 1:1 ratio, and we are allowed to resize the hash
     * table (global setting) or we should avoid it but the ratio between
     * elements/buckets is over the "safe" threshold, we resize doubling
     * the number of buckets. */
    if (d->ht[0].used >= d->ht[0].size &&
        (dict_can_resize ||
         d->ht[0].used/d->ht[0].size > dict_force_resize_ratio)) 
    {
        return dictExpand(d, d->ht[0].used*2);
    }
    return DICT_OK;
}
```

从判断是否扩容的代码可以看到扩容的条件

- 确定配置的可以扩容
- hash的成员数量(使用量 used) / bucket数量 (size) > 5


综合来说，redis的dict在减少和增加元素时候会触发是否进行"缩容" 和 "扩容"的判断，判断的标准是 dict 累计的元素数量 和 bucket的数量的比值来确定是否触发

- 减少元素情况下，比值 小于 10%，触发缩容
- 增加元素情况下，比值 大于 5倍，触发扩容


**第三个问题：什么时候推动rehash**

既然rehash是缓步进行，一次处理不完，那么redis的作者必然要考虑在什么时候去推动rehash，通过代码，我们知道在五个地方都进行rehash的推动，说明一下，"推动"，说明redis的rehash已经被触发，rehashidx > -1

有哪五个步骤呢

1. dict 增加元素 `dictEntry *dictAddRaw(dict *d, void *key)`
2. dict 删除元素 `static int dictGenericDelete(dict *d, const void *key, int nofree)`
3. dict 查询 `dictEntry *dictFind(dict *d, const void *key)`
4. dict 获取随机的key  `dictEntry *dictGetRandomKey(dict *d)`
5. dict 从随机资源中获取部分key `unsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) `

我们能看出来，基本在dict的查询已经变动中，都会查看dict是否在rehash中，如果在rehash中，则推动rehash进程，一次推动希望迁移的bucket数量是1个


### 3.5 sds

sds : `A C dynamic strings library`

redis作者针对string设计了一个简单的动态字符串操作库，非常经典， 在我看来，c里面字符串的操作面临下面的几个问题

- 字符串的长度判断通常是 ‘\0’ 结尾判断，而在一些比较长的字符串中，例如视频、图片二进制中，会有'\0'存在，导致字符串操作中被意外截断
- 字符串的频繁变化，例如 set key value ， 那么 value 在做变化的时候，传统的字符串处理将带来非常大的难度

对字符串的设计有很多种方案，例如 nginx 采用一个struct 设计两个成员变量， 一个`char *`来保存一个字符串的 头 指针，另外 `int` 来保存字符串的长度，这种方式解决了`\0`的问题， 但是解决不了上述的第二种情况

redis设计了一个更加丰富的头部数据结构来描述申请的字符串， 我们来看一下数据结构

```c
/* Note: sdshdr5 is never used, we just access the flags byte directly.
 * However is here to document the layout of type 5 SDS strings. */
struct __attribute__ ((__packed__)) sdshdr5 {
    unsigned char flags; /* 3 lsb of type, and 5 msb of string length */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len; /* used */
    uint8_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr32 {
    uint32_t len; /* used */
    uint32_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr64 {
    uint64_t len; /* used */
    uint64_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
```

这里面有几点需要说明一下

1. sdshdr5 数据结构目前没有用到
2. sds的数据结构包含核心的几个成员变量
    - len 标识申请的 内存使用的情况
    - alloc 表示申请的内存长度，这个长度不包括sds头部指针
    - flags flags表示的字符串的类型，可以看一下下面的代码，根据申请的内存大小，分成了5个类别, 其中下面第一个类别暂时不支持
        1. 申请的内存             小于等于 32
        2. 申请的内存 大于   32， 小于等于 256
        3. 申请的内存 大于  256， 小于等于 64k
        4. 申请的内存 大于  64k,  小于等于 4G 
        5. 申请的内存 大于   4G
    - buf[] 设定空数组，不占用空间，在缓冲池设计中经常使用

```c
static inline char sdsReqType(size_t string_size) {
    if (string_size < 1<<5)
        return SDS_TYPE_5;
    if (string_size < 1<<8)
        return SDS_TYPE_8;
    if (string_size < 1<<16)
        return SDS_TYPE_16;
    if (string_size < 1ll<<32)
        return SDS_TYPE_32;
    return SDS_TYPE_64;
}
```

3. 结构体选择 `__attribute__ ((__packed__))` 是希望头部成员变量分配是紧凑的，那么可以通过一次偏移就获取结构体的成员变量

![]({{site.baseurl}}/img/tech/2020-05-12-17-23-58.png)


查看上面的图，sds选择在不同类型下用不同的的sds头部来描述申请的内存信息，怎么获取sds头部的数据类型呢，其实比较简单

1. 首先 sds向左偏移一个 char指针长度，获取头部flags信息 `sds s; s[-1]`
2. 通过flags 获取sds头部类型，通过偏移获取使用长度和malloc的内存长度


 了解redis作者设计的sds数据结构，其实基本知道sds提供的基本功能，例如，字符串的拼接，trim，compare 等等，这里就不细述了


### 3.6 ziplist

### 3.7 cluster

### 3.8 client

### 3.9 server



## 四. redis-server的启动流程

## 五. redis的内存管理机制


## 六. lua脚本在redis中的使用和实现

## 八. redis的持久化

## 九. redis的部署篇


## 十.参考文献
1. 百度百科redis介绍 https://baike.baidu.com/item/Redis/6549233?fr=aladdin
2. 维基百科redis介绍 https://zh.wikipedia.org/wiki/Redis
3. redis命令参考 http://redisdoc.com/ 